---
title: "Analysis of Milk Spectral Data"
author: "Gautam Malhotra"
date: "15/03/2022"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
```

```{r Libraries}
require(e1071)
require(ggplot2)
require(dplyr)
require(dendextend)
require(rgl)
require(pls)
require(caret)
```
The MIR data contains 403 recorded observations of various traits of milk samples.  
The last 531 columns of this data contains the MIR Spectra readings on 531 unique wave-lengths  
```{r Importing Data}
# Importing Data set 
MIR_Traits_Data <- read.csv("Milk_MIR_Traits_data.csv")
# Setting seed
set.seed(216)
#Generating the random number corresponding to the row to be removed
index_removed <- round(runif(1,min=1,max=nrow(MIR_Traits_Data)))
#Removing row
MIR_Traits_Data<-MIR_Traits_Data[-index_removed,]
```

```{r}
str(MIR_Traits_Data[,1:10])
```


```{r}
# Selecting Data pertaining to the Spectra
Spectra_Data <- MIR_Traits_Data[,(ncol(MIR_Traits_Data)-530):ncol(MIR_Traits_Data)]
# Checking for Missing values
paste("Number of Missing values:",sum(is.na(Spectra_Data)))
```
#### Visualizing the Spectra

```{r Visualization}
# Randomly Choosing an observation 
random_observation <-  sample(c(1:nrow(Spectra_Data)),1)
# Obtaining column names
col_names <- colnames(Spectra_Data)
# Changing column names into list of corresponding wavelengths
col_names <- as.numeric(gsub("X","",col_names))
p1<-ggplot()+geom_point(aes(x = col_names,y = unlist(Spectra_Data[random_observation,])))+xlab("Wavelength  cm−1")+ylab("Absorbance Values")+ggtitle(paste("MIR_Spectra of obervation no:",random_observation))
# Generating more tick for a more accurate plot
p1 + scale_x_continuous(n.breaks = 20) +scale_y_continuous(n.breaks = 20)
```
  
This graph represents the MIR_spectra for the `r random_observation` observation in our data set.  
The graph plots the absorbance values of this sample at each of the 531 recorded wavelengths.  
Each wavelength has the potential to correspond to the different traits of the sample such as the Heat stability,milk fat content, protein content ,processability etc, the absorbance values at these wavelengths indicate the strength of these traits.  

```{r}
matplot(t(Spectra_Data),xlab = "Wavelength Index",ylab = "Absorbance",main="Trend of Spectra")
```
  
We can see that the wavelengths are overlapping to a great extent , this indicates that there is high correlation among those wave-lengths.  
We can also see that the maximum absorbance in the spectra is around 0.64 and the minimum absorbance is approximately -0.1  

```{r Alpha s1 Casine}
# Subsetting Required Data
A_S1_Casine<-MIR_Traits_Data$alpha_s1_casein
p2<-ggplot()+geom_boxplot(aes(x=A_S1_Casine),color="#69b3a7",fill="#69b3a2",alpha=0.6)+xlab(" αs1-casein values")+ ggtitle("αs1-casein Boxplot [All observations]")
p2+ scale_x_continuous(n.breaks = 10) +scale_y_continuous(n.breaks = 10)
```
  
$\alpha s_1Casine$ is a protein trait present in milk.  
This boxplot indicates that  50% of $\alpha s_1Casine$ lie between approximately 12 and 15.5  
We are presented with few outliers in our observations.  

```{r}
ggplot()+geom_histogram(aes(x=A_S1_Casine),color="#69b3a7",fill="#69b3a2",alpha=0.6)+xlab(" αs1-casein values")+ ggtitle("αs1-casein Boxplot [All observations]")+scale_x_continuous(n.breaks = 10) +scale_y_continuous(n.breaks = 10)
```
  
Most common alpha s1 casein values seem to be approximately between 12.5 and 14
  
To be noted: We have 124 observations which do not have a recorded value for this variable
  
```{r Removing outliers}
# Subsetting Data to only contain observations that have:
# A recorded value for alpha_s1_casein
# The value lies between 3 standard deviations of the mean 
Data_sub<-subset(MIR_Traits_Data,(alpha_s1_casein>mean(A_S1_Casine,na.rm=T)-3*sd(A_S1_Casine,na.rm = T)&alpha_s1_casein<mean(A_S1_Casine,na.rm=T)+3*sd(A_S1_Casine,na.rm = T)))
```
We end up removing `r length(MIR_Traits_Data)-length(Data_sub)` observations from our working data-set  

### Clustering

I choose to perform k-means clustering before hierarchical clustering since using k-means we can use WSS as an indication of how many clusters would be optimum for our data.  

```{r K-means Clustering}
Spectra_Data_subset <- Data_sub[,(ncol(Data_sub)-530):ncol(Data_sub)]
WGSS = rep(0,10)
n = nrow(Spectra_Data_subset)
WGSS[1] = (n-1) * sum(apply(Spectra_Data_subset, 2, var))
for(k in 2:10)
{
WGSS[k] = sum(kmeans(Spectra_Data_subset, centers = k,nstart = 50)$withinss)
}
plot(1:10, WGSS, type="b", xlab="No.of Clusters", ylab="Within group sum of squares",main = "WSS Elbow plot")+abline(v=4,lty=2,col="skyblue")
```
  
The plot above shows the WSS for corresponding number of clusters, choosing the optimum number of clusters is a subjective choice we need to make now before moving forward with the clustering algorithms .  

I chose that k = 4 as a good choice . This is because the curve (WSS vs number of clusters) starts to flattens out after 4,implying that increasing the clusters anymore would only result in over-fitting of the data.  

```{r k-means cluster}
# using nstart = 50 to avoid local optimum 
Spectra_k = kmeans(Spectra_Data_subset, center=4,nstart = 50)
Data_sub_kmeans<- mutate(Data_sub,cluster =Spectra_k$cluster)
table(Spectra_k$cluster)
```

Our k-means clustering suggests that our data is divided into 4 clusters  
Cluster 1 : 8 observations  
Cluster 2 : 81 observations  
Cluster 3 : 130 observations  
Cluster 4 : 84 observations  

```{r Plotting Clusters}
ggplot(data = Data_sub_kmeans) + geom_point(aes(x=c(1:nrow(Data_sub_kmeans)),y=cluster,color=cluster))+xlab("Observation Index")+ylab("Cluster Assigned")+ggtitle("Cluster distribution")
```
  
Clusters 3 contain majority of the observations.  
Clusters 2 and 4 are of approximately equal sizes  
The clustering does not seem to be dependent on in what order these observations were made in the data set
  
If we explore the data based on clusters , we find that the lactose content and Casein Content of observations in cluster 1 is significantly less than of the other clusters.  
```{r Lactose_Content K means}
temp <- data.frame(c1<-c(head(Data_sub_kmeans[Data_sub_kmeans$cluster==1,]$Lactose_content)),c2<-head(Data_sub_kmeans[Data_sub_kmeans$cluster==2,]$Lactose_content),c3<-head(Data_sub_kmeans[Data_sub_kmeans$cluster==3,]$Lactose_content),c4<-head(Data_sub_kmeans[Data_sub_kmeans$cluster==4,]$Lactose_content))
names(temp)<-c("c1","c2","c3","c4")
print("Lactose Content")
print(temp)
```


```{r}
boxplot(temp,main="Lactose Content [k-means]",ylab="Lactose Content",xlab="Cluster")
```

```{r Casein_Content k_means}
temp <- data.frame(c1<-c(head(Data_sub_kmeans[Data_sub_kmeans$cluster==1,]$Casein_content)),c2<-head(Data_sub_kmeans[Data_sub_kmeans$cluster==2,]$Casein_content),c3<-head(Data_sub_kmeans[Data_sub_kmeans$cluster==3,]$Casein_content),c4<-head(Data_sub_kmeans[Data_sub_kmeans$cluster==4,]$Casein_content))
names(temp)<-c("c1","c2","c3","c4")
print("Casein Content")
print(temp)
```

```{r}
boxplot(temp,main="Casein Content[k-means]",ylab="Casein Content",xlab="Cluster")
```

```{r Hierarichal Clustering}
# We use the euclidean distance for the dissimilarity matrix construction
# Since we removed the outliers from the data, it's disadvantage of being sensitive to outliers is removed making it an appropriate measure. 
dist_Spec = dist(Spectra_Data_subset,method = "euclidean")
# Using the complete linkage to create the hierarchical classification

# Average and complete linkage are generally preferred over single linkage, as they tend to yield
# more balanced dendrograms.
H_Classified <- hclust(dist_Spec, method = "complete")
# Plotting the cluster Dendogram
#plot(H_Classified,xlab = "Average Linkage",cex=0.3)
```

  
Now that we have the Hierarchical Classification , we need to determine how many clusters (classes) are we testing for. In this assignment I have chosen to classify into 4 different clusters  
```{r}
H_4_Classified<-cutree(H_Classified,k=4)
Data_sub_Hier<- mutate(Data_sub,cluster = H_4_Classified)
paste("We classified the observations in the following way:")


table(H_4_Classified)
```

```{r}
avg_dend_obj <- as.dendrogram(H_Classified)
avg_dend_obj<-color_branches(avg_dend_obj,k=4)
avg_col_dend <- color_branches(avg_dend_obj, h = 1.1)
plot(avg_col_dend,main ="Visual Representation of the Clusters")
legend("topright", legend = c(1,2,3,4),fill = c("#AAA3C0","#BCE5E4","#9D9F72","#95636F"))
```
  
Exploring whether there is any emerging structure in the classification
  
If we explore the data based on clusters , we find that the lactose content of observations in cluster 3 is significantly less than of the other clusters.
  
This is just an observation and not implying that the lactose content of the sample is the sole factor dictating the clustering .
  
```{r Lactose_Content}
temp <- data.frame(c1<-c(head(Data_sub_Hier[Data_sub_Hier$cluster==1,]$Lactose_content)),c2<-head(Data_sub_Hier[Data_sub_Hier$cluster==2,]$Lactose_content),c3<-head(Data_sub_Hier[Data_sub_Hier$cluster==3,]$Lactose_content),c4<-head(Data_sub_Hier[Data_sub_Hier$cluster==4,]$Lactose_content))
names(temp)<-c("c1","c2","c3","c4")
print("Lactose Content")
print(temp)
```

```{r}
boxplot(temp,main="Lactose Content")
```
  
The same trend is found for Casein Content. It is an interesting observation since casein and lactose are not directly related with casein being a protein and lactose being a sugar.
  
```{r Casein_Content}
temp <- data.frame(c1<-c(head(Data_sub_Hier[Data_sub_Hier$cluster==1,]$Casein_content)),c2<-head(Data_sub_Hier[Data_sub_Hier$cluster==2,]$Casein_content),c3<-head(Data_sub_Hier[Data_sub_Hier$cluster==3,]$Casein_content),c4<-head(Data_sub_Hier[Data_sub_Hier$cluster==4,]$Casein_content))
names(temp)<-c("c1","c2","c3","c4")
print("Casein Content")
print(temp)
```
```{r}
boxplot(temp,main="Caesin Content")
```

```{r}
par(mfrow=c(2,2))
boxplot(Data_sub_Hier[Data_sub_Hier$cluster==1,3:7])
title(main = "Cluster 1")
boxplot(Data_sub_Hier[Data_sub_Hier$cluster==2,3:7])
title(main = "Cluster 2")
boxplot(Data_sub_Hier[Data_sub_Hier$cluster==3,3:7])
title(main = "Cluster 3")
boxplot(Data_sub_Hier[Data_sub_Hier$cluster==4,3:7])
title(main = "Cluster 4")
```
  
From the Box plots above we also notice that different clusters have the DaysInMilk as a distinguishing factor.
  
For cluster 1: The DaysInMilk majority of its values lying between the 1st and 2nd quartile with 50% of values between the range of 44 and 194
  
For cluster 2: The DaysInMilk is mostly similarly distributed as cluster one but more values lie below the median in this cluster
  
For cluster 3: The DaysInMilk is seemingly evenly distributed with a very compact Inter Quartile Range lying approximately between 29 and 60 
  
For cluster 4: The DaysInMilk has a very large Inter Quartile Range approximately from 12 to 230
  
```{r ARI}
classAgreement(table( H_4_Classified,Spectra_k$cluster))$rand
```
  
This measure tells us how agreeable or similar the two classifications are.
  
Here we get that the two are approximately 69% alike
   
**From both clustering algorithms applied we notice that samples which contain relatively low casein and lactose contents are being clustered together.**
  
#### PCA

First we must make the decision of whether we need to standardize the data or not.  
If the variance related to the variables are different then we shall standardize the data. Variables with larger variances will end up having more effect on the PCA.  

Upon finding the variance we see there is a difference in the variance of the variables  

```{r}
sample(apply(Spectra_Data_subset,2,var),10)
```

Although the variation values are extremely small in all variables, it is to be noted that there is a difference of 10 to 100 times . I consider this sufficient to standardize the data.  

```{r Standardizing data}
# using the scale() function to scale our data
Spectra_Data_subset_std <- 
  scale(Spectra_Data_subset,center = T,scale = T)
```

```{r PCA}
Spectra_PCA <- prcomp(Spectra_Data_subset_std,scale. = T,center = T)
PCA_sum <- summary(Spectra_PCA)
# Displaying the first 10 Principle components
PCA_10 <-as.data.frame(t(PCA_sum$importance[,1:10]))
PCA_10
```

```{r Cumilative Poroportion Plot}

ggplot(data = PCA_10,aes(x=1:10,y= `Cumulative Proportion`,label = round(`Cumulative Proportion`,3)))+
  geom_point()+
  geom_line()+
  geom_text(hjust =0.5,vjust=1.4,size=3)+
  scale_x_continuous(n.breaks =10)+
  xlab("Principal Component")+
  ylab("Cumilative Variance Proportion")+
  ggtitle("Cumulative proportion of Variance explained by the first 10 Principal Components")+
  geom_vline(xintercept = 4,linetype="dotted")
```

I use the following method to choose the number of Principal Components required to represent the data:  

#### Scree Plot
A scree plot visualizes the proportion of variance explained by the principal component  
We use this plot to find the point at which the proportion of variance for each subsequent point is very small or practically none.  

We only plot the first 10 components since they are created in order of increasing variation explained, by the 10th principal component the amount of variation explained is less that .006% of the total variation present in the data.  
Exploring any more components is not worth the computational resources.
  
```{r Scree Plot}
ggplot(data = PCA_10,aes(x=1:10,y= `Proportion of Variance`,label = `Proportion of Variance`))+
  geom_point()+
  geom_line()+
  geom_text(hjust =0.5,vjust=1.4,size=3)+
  scale_x_continuous(n.breaks =10)+
  xlab("Principal Component")+
  ylab("Cumilative Variance Proportion")+
  ggtitle("Scree Plot of the first 10 Principal Components")+
  geom_vline(xintercept = 4,linetype="dotted")
```
  
We find the drop off at the 4the component implying that we should take the first 4 components.  

Upon performing principal component analysis we see that using the first 4 Principal Components we retain 98.2% of the variation(Information) present in the data.  
This is a massive reduction from the 531 variables we had originally.  
Thus, we will be using the first 4 principle components to represent the data.  

```{r Scores from Predict}
# Getting the scores using predict for validation
test_component_scores = predict(Spectra_PCA)
head(test_component_scores[,1:4])
```

```{r Scores First Principles}
S =cov(scale(Spectra_Data_subset))
eig = eigen(S)
e_vec = eig$vectors
scores <- as.matrix(scale(Spectra_Data_subset,center=T))%*%e_vec
scores[1:6,1:4]
```

We see that some of the scores have the opposite direction but equal magnitude when compared to the predicted scores.  
This is because the eigen decomposition in R is not always correct. This is mentioned clearly in the help page for the function eigen()  


```{r}
ggplot(data = data.frame(scores),aes(x=X1,y=X2))+geom_point()+ggtitle("PC1 vs PC2")+geom_vline(xintercept = -37.5,linetype="dotted",col="blue",lwd=1)+geom_hline(yintercept = -25,linetype="dotted",col="red",lwd=1)
```
  
By plotting PC1 vs PC2 scores we can see a structure emerging. It seems as though the data gets divides into 2 clusters:  
Cluster 1 with a PC1 score >=-37.5 and PC2 score >=-25  
Cluster 2 with a PC1 score <=-37.5 and PC2 score <=-25  

### PLSR

```{r}
# Manipulating data to get alpha s1 casein and Spectra Data in the same data frame
Data_plsr <- Data_sub[,c(9,52:582)]

#Splitting data into test and train
test_index <- createDataPartition(Data_plsr$alpha_s1_casein,times = 1,p=0.33,list = F)
train_data <- Data_plsr[-test_index,]
test_data  <- Data_plsr[test_index,]
```


```{r}
# Fitting the model
pls_fit <- plsr(alpha_s1_casein~.,data=train_data,scale=T,validation = "CV")
validationplot (pls_fit , val.type = "RMSE",legendpos="topright",main="RMSEP Plot for alpha s1 Casein")
```
  
This plot shows that the RMSEP value decreases and then increases over the number of components,implying that the optimal number of components is low   
A closer look at the plot allows us to obtain the optimum number of components  
```{r}
validationplot (pls_fit , val.type = "RMSE",legendpos="topright",main="RMSEP Plot for alpha s1 Casein",xlim = c(0,10),ylim=c(1.5,3))+abline(v=4,lty=2)
```
The optimum number of clusters for us is 4  
we can confirm this decision by cumulative variation captured by the first 10 components  
```{r}
cumsum(explvar(pls_fit)[1:10])
```
  
By component 4 we have already captured approximately 98% of our variance
  
```{r}
 plot(pls_fit, ncomp = 4, asp = 1, line = TRUE,main="Cross validated predictions for Spectra Data")
```
  
This plot shows the cross-validated predicted values using 4 components against measure values. Since the points are following the target line we can confirm that using 4 components is sufficient for our data
  
##### Prediction

```{r Predicting}
# Predicting using our model on test data
alpha_casein_predicted<-predict(pls_fit, ncomp = 4, newdata = test_data)
alpha_casein_predicted %>% head()
```

```{r}
ggplot(data = data.frame(alpha_casein_predicted),aes(x=1:length(alpha_s1_casein.4.comps),y=alpha_s1_casein.4.comps,color="Predicted"))+geom_line()+geom_point(aes(x=1:length(alpha_s1_casein.4.comps),y=test_data$alpha_s1_casein,color="Observed"))+theme_gray()+xlab("Test Observation Index")+ylab("Alpha s1 casein values")+ggtitle("Alpha casein prediction using PLSR")
```
  
The predicted values seem to follow the test values quite closely.
  
We use RSMEP to evaluate it's performance
  
```{r}
RMSEP_comparison<-data.frame(x1<-(RMSEP(pls_fit)$val)[seq(2,20,2)],x2<-(RMSEP(pls_fit,newdata = test_data)$val)[seq(2,20,2)])
names(RMSEP_comparison)<-c("Cross validated estimate","test RMSEP")
RMSEP_comparison[4,]
```

Since the test value is close to the estimated value indicating that our prediction was a good one.
  
```{r}
pls_predictions <-predict(pls_fit,test_data)
pls_predictions<-matrix(pls_predictions,nrow = nrow(test_data),ncol = 179,byrow = FALSE)
pls_predictions<-as.data.frame(pls_predictions)
paste("RMSE for predictions:",
sqrt(mean((pls_predictions$V4 - test_data$alpha_s1_casein)^2)))
```
  
### PLSR without pls package

```{r}
#X = Spectra_Data_subset
#Y = matrix(data = Data_sub$alpha_s1_casein,nrow = 303,ncol = 1,byrow = T)

#Splitting data into test and train
test_index <- createDataPartition(Data_plsr$alpha_s1_casein,times = 1,p=0.33,list = FALSE)
X <- as.matrix(Data_plsr[-test_index,2:ncol(Data_plsr)])
Y  <- Data_plsr[-test_index,1]
Y<-matrix(Y,nrow = 200,ncol = 1,byrow = TRUE)

W <- list()
T_list <- list()
P <- list()
Q <-list()
E<-list()
F_list<-list()


En = as.matrix(X)
Fn = as.matrix(Y)

for(i in 1:4)
{
S = t(En)%*%Fn
#calculating svd and seperating the first left and right eigen vectors
w = svd(S)$u
q = svd(S)$v

Tn = En%*%w
u = Fn%*%q
# Normalizing scores
Tn = c(Tn/(sqrt((t(Tn)%*%Tn)[1,1])))

# Regressing over the scores to obtain remaining unexplained variation
p = t(En)%*%Tn
q = t(Fn)%*%Tn

En = En-(Tn%*%t(p))
Fn = Fn-(Tn%*%t(q))


T_list<-cbind(T_list,Tn)
P<-cbind(P,p)
Q<-cbind(Q,q)
W<-cbind(W,w)
}

# Converting columns of matrices to doubles
W<-as.matrix(W)
W = apply(W,2,as.numeric)

T_list<-as.matrix(T_list)
T_list = apply(T_list,2,as.numeric)

P<-as.matrix(P)
P = apply(P,2,as.numeric)

Q<-as.matrix(Q)
Q = apply(Q,2,as.numeric)

R = as.matrix(W) %*% solve((t(as.matrix(P))%*%as.matrix(W)))
# Obtaining are coefficients of regression
B = R%*%(Q)
```

```{r Manual plsr Prediction}

X_test<- as.matrix(Data_plsr[test_index,2:ncol(Data_plsr)])
Y_test  <- Data_plsr[test_index,1]

# predicting using obtained coefficients and Test data
prediction_plsr <- as.matrix(X_test)%*%as.matrix(B)
paste("RMSE for predictions",sqrt(mean((prediction_plsr - Y_test)^2)))
```
  
When comparing RMSE obtained by using pls package(1.81289) , we can see that our model performed worse than it.
  
```{r}
ggplot(data = data.frame(prediction_plsr),aes(x=1:length(prediction_plsr),y=prediction_plsr,color="Predicted"))+geom_line()+geom_point(aes(x=1:length(prediction_plsr),y=Y_test,color="Observed"))+xlab("Index")+ylab("alpha s1 casein")+ggtitle("Alpha s1 casein prediction using plsr [wihtout pls package]")
```
  
Although our predictions are generally speaking good, but in comparison to our previous plsr model it fall behind slightly.
  